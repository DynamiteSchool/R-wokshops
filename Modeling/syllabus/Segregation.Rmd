---
title: "Modelling"
author: "CC&PC"
date: "Summer School"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(githubinstall)
library(rmapzen)
library('leaflet')
library(hrbrthemes)
library(devtools)
library(ggrepel)
install_github("mountainMath/cancensusHelpers")
library(sf)
library(cancensus)
library(RColorBrewer)
library(cancensusHelpers)
library(data.table)

```

C. Anderson provokingly in the magazine Wired: 

> "The End of Theory: the data deluge makes the scientific method obsolete"

## Why model?


J. Epstein (2008, JASSS): 'Why model?'

* Explain (very distinct from predict)
* Guide data collection
* Illuminate core dynamics
* Suggest dynamical analogies
* Discover new questions
* Promote a scientific habit of mind
* Bound (bracket) outcomes to plausible ranges
* Illuminate core uncertainties.
* Offer crisis options in near-real time
* Demonstrate tradeoffs / suggest efficiencies
* Challenge the robustness of prevailing theory through perturbations
* Expose prevailing wisdom as incompatible with available data
* Train practitioners
* Discipline the policy dialogue
* Educate the general public
* Reveal the apparently simple (complex) to be complex (simple)

A model is a simplified representation/abstraction of a target system, which implements some theoretical propositions about the logical linkages between objects of interest.

In this tutorial, two kinds of models are presented: 

* descriptive models (statistics)
* generative models (ABM)

More generally, we want to show how the two shed complementary lights on spatial problems and how they interact with the new massive data.

### Case study: urban segregation with scraped AirBnB data

```{r censussettings , include=FALSE}
options(cancensus.api_key = "CensusMapper_5d949dee7f3e2546720b77d6ef08072e")
ct = "35535"
cm = "24462"
cv = "59933"
```

##The data
Let's bind together the data for all three cities
```{r data}
f = list.files('insideairbnb/')

mont <- read.csv(paste0('insideairbnb/', f[1]))
toro <- read.csv(paste0('insideairbnb/', f[2]))
vanc <- read.csv(paste0('insideairbnb/', f[3]))

toronto = unique(toro$city)
vancouver = unique(vanc$city)
montreal = unique(mont$city)

df = rbind(mont, toro, vanc)
```

Cleaning here is choosing how to make the data at hand in line with the purpose of the analysis.

First, if we want to take airbnb listings as proxies for residents, we need to identify and remove commercial lettings, as well as listings in neighbourhoods which are different from the host's neighbourhood, as well as multiproperties.
```{r cleaningpropertytype}
l <- levels(df$property_type)
lookup = data.frame('type' = 1:length(l))
lookup$type <- as.factor(l)
lookup$property_group <- c(
# [1] "Aparthotel"             "Apartment"              "Bed and breakfast"      "Boat"                   "Boutique hotel"         "Bungalow"               "Cabin"                 
'hotel', 'home', 'hotel', 'other', 'hotel', 'home', 'other',
  #  [8] "Camper/RV"              "Campsite"               "Casa particular (Cuba)" "Cave"                   "Chalet"                 "Condominium"            "Cottage"               
'other', 'other', 'home', 'other', 'home', 'home', 'home',
# [15] "Farm stay"              "Guest suite"            "Guesthouse"             "Hostel"                 "Hotel"                  "House"                  "Houseboat"             
'home', 'home', 'hotel', 'hotel', 'hotel', 'home', 'home',
# [22] "Hut"                    "Loft"                   "Nature lodge"           "Other"                  "Serviced apartment"     "Tent"                   "Timeshare"             
'other', 'home', 'other', 'other', 'hotel', 'other', 'other',
# [29] "Tiny house"             "Townhouse"              "Villa"                  "Barn"                   "Castle"                 "Dorm"                   "Earth house"           
'home', 'home', 'home', 'home', 'home', 'hotel', 'other',
# [36] "In-law"                 "Parking Space"          "Treehouse"              "Resort"            
'home', 'other', 'other', 'hotel'
)

df = data.frame(df,lookup[match(df$property_type, lookup$type),] )
 # dfh = subset(df, property_group == 'home' & as.character(df$host_neighbourhood) == as.character(df$neighbourhood) & df$room_type != "Shared room")
dfh = subset(df, property_group == 'home' & as.character(df$host_neighbourhood) == as.character(df$neighbourhood))
dfh$property_group <- NULL
dfhu = dfh[!duplicated(dfh$host_id),]
dim(df)
dim(dfhu)
```

then we want to keep current listings, i.e. whose last review dates back from less than 2 years for example
```{r cleaninginactive}
dfhu$year = as.numeric(substr(dfhu$last_review, 1, 4))

 # pal <- colorFactor(
 #    palette =  brewer.pal(n=10, 'Blues'),
 #    domain = dfhu$year
 #  )

# leaflet() %>% addProviderTiles("CartoDB.Positron") %>%
#   addCircleMarkers(
#     data = dfhu,
#         radius = ~ sqrt(0.07 * numPrice),
#     lat = ~ latitude,
#     color = ~pal(year),
#     stroke = FALSE,
#     fillOpacity = 0.5,
#     layerId = ~ id,
#     lng = ~ longitude
#   ) %>%  addLegend(pal = pal, position = 'topleft', values = dfhu$year)
# 

dfhun = subset(dfhu, year >= 2017)
dim(df)[1]
dim(dfhun)[1]
```

Then, we want to use a price variable that is usable (e.g. numeric) and to normalise the price by a measure of size: the number of rooms because square feet is mostly not filled by hosts. This implies to remove the small number of shared rooms
```{r createnormalisedprice}
dfhun$numPrice <- as.numeric(gsub("[$]",'',dfhun$price))
summary(dfhun$room_type)
final = subset(dfhun, room_type != "Shared room")

final$rooms = ifelse(final$bedrooms == 0, 1, final$bedrooms)
final$priceperroom = as.numeric(ifelse(final$room_type == T,  final$numPrice,  final$numPrice / final$rooms))
```

Let's retrieve census shape files and data from the census API
```{r prepmap, include=FALSE}

city = "montreal"


if(city == "toronto"){
  citynames = toronto
  censuscode = ct
}
if(city == "vancouver"){
  citynames = vancouver
  censuscode = cv
}
if(city == "montreal"){
  citynames = montreal
  censuscode = cm
}

city_data = subset(final, city %in% citynames)

## Identifying the vectors for visible Minority status
parent_vector <- "v_CA16_3954"
minorities <- list_census_vectors("CA16") %>% 
  filter(vector == "v_CA16_3954") %>% 
  child_census_vectors(leaves_only = TRUE) %>% 
  pull(vector)

minority_vectors <- c(parent_vector, minorities)

cma.ct <- get_census("CA16", regions=list(CMA=censuscode), 
                       vectors = minority_vectors, level = "CT",
                       labels = "short", geo_format = NA)
  cma.csd <- get_census("CA16", regions=list(CMA=censuscode), 
                        vectors = minority_vectors, level = "CSD",
                        labels = "short", geo_format = NA)
 
   csd.geo <- get_census_geometry("CA16", regions=list(CSD=censuscode), 
                                 level = "CT", geo_format = "sf")
  
  csd.csd.geo <- get_census_geometry("CA16", regions=list(CSD=censuscode), 
                                     level = "CSD", geo_format = "sf")
```
  
  and map!
  
```{r map}

  pal <- colorQuantile(
     palette =  'Blues',
     domain = city_data$priceperroom,
     n = 10
   )

  map <- leaflet() %>% addProviderTiles("CartoDB.Positron") %>%
      addPolygons(
      data = csd.csd.geo,
      color = 'black',
      fill = F,
      weight = 0.7,
      opacity = 0.9
    ) %>% addPolygons(
      data = csd.geo,
      color = 'grey',
      fill = F,
       weight = 0.4
    ) %>%
  addCircleMarkers(
    data = city_data,
        radius = ~ sqrt(4 * rooms),
    lat = ~ latitude,
    fillColor = ~ pal(priceperroom),
    color = 'black',
    stroke = T,
    fillOpacity = 0.5,
   weight = 0.1,
    layerId = ~ id,
    lng = ~ longitude
  ) %>% 
  addLegend(pal = pal, position = 'topleft', values = city_data$priceperroom)

 map
 
```
 


  and map!
  
```{r diversitymapprep, include=F}
 
diversity_index <- function(cma) {
   
   cma.ct <- get_census("CA16", regions=list(CMA=cma), 
                       vectors = minority_vectors, level = "CT",
                       labels = "short", geo_format = NA)
  
  # Calculating diversity (Theil's E)
  # For every variable, divide by v_CA16_3999 and multiply times the logged inverse proportion, then
  # take the sum for each tract. With 14 different groups, the max entropy is ln(14) = 2.64
  base_pop <- quo(v_CA16_3954)
  cma.ei <- cma.ct %>% 
    group_by(GeoUID) %>% 
    mutate_at(minorities, funs(S = ./!!base_pop)) %>%
    mutate_at(vars(ends_with("_S")), funs(E = -.*(log(.)))) %>%
    select(GeoUID, ends_with("_S_E")) %>% 
    ungroup() %>% 
    mutate_at(vars(ends_with("_S_E")), funs(ifelse(is.nan(.),0,.))) %>% 
    mutate(Ei = rowSums(select(.,-1), na.rm = FALSE)) %>% 
    select(GeoUID, Ei)
  
   # Join with geography
  
  cma.geo <- get_census_geometry("CA16", regions=list(CMA=cma), 
                                 level = "CT", geo_format = "sf")
  cma.ct <- cma.geo %>% 
    left_join(cma.ei) %>% 
    mutate()
  
  return(cma.ct)
}
  
tractTable <- diversity_index(censuscode)
```

```{r diversitymap}

  pal <- colorQuantile(
     palette =  'Blues',
     domain = city_data$priceperroom,
     n = 10
   )
      pal2 <- colorQuantile(
     palette =  'Reds',
     domain = tractTable$Ei,
     n = 10)

   map <- leaflet() %>% addProviderTiles("CartoDB.Positron") %>%
      addPolygons(
      data = csd.csd.geo,
      color = 'black',
      fill = F,
      weight = 0.7,
      opacity = 0.9
    ) %>% addPolygons(
      data = tractTable,
      color =  ~ pal2(Ei),
      fill = ~ pal2(Ei),
       weight = 0.4
    ) %>%
  #addCircleMarkers(
  #   data = city_data,
  #       radius = ~ sqrt(4 * rooms),
  #   lat = ~ latitude,
  #   fillColor = ~ pal(priceperroom),
  #   color = 'black',
  #   stroke = T,
  #   fillOpacity = 0.5,
  #  weight = 0.1,
  #   layerId = ~ id,
  #   lng = ~ longitude
  # ) %>% 
# addLegend(pal = pal, position = 'topleft', values = city_data$priceperroom)%>% 
  addLegend(pal = pal2, position = 'topleft', values = tractTable$Ei)
 
   map
```


```{r segmapprep, include=F}

  cma.eict <- tractTable
  
  cma.csd <- get_census("CA16", regions=list(CMA=censuscode), 
                        vectors = minority_vectors, level = "CSD",
                        labels = "short", geo_format = NA)
 
  cma.eicsd <- cma.csd %>%
    group_by(GeoUID,`Region Name`, Population) %>%
    mutate_at(minorities, funs(S = ./!!base_pop)) %>%
     mutate_at(vars(ends_with("_S")), funs(E = -.*(log(.)))) %>%
        select(GeoUID, `Region Name`, Population, ends_with("_S_E")) %>% 
    ungroup() %>%
    mutate_at(vars(ends_with("_S_E")), funs(ifelse(is.nan(.),0,.))) %>%
    mutate(Ei = rowSums(select(.,-c(1,2,3)), na.rm = FALSE)) %>%
    mutate(CMA = censuscode) %>%
    select(CMA, GeoUID, `Region Name`, Population, Ei)
  
  dfseg <- data.frame(cma.eict, cma.eicsd[match(cma.eict$CSD_UID, cma.eicsd$GeoUID),])

  cma.h <- dfseg  %>%
     select(GeoUID, CSD_UID, name = `Region.Name`, ctpop = Population,
           csdpop = Population.1, ctei = Ei, csdei = Ei.1)  %>%
    filter(csdpop > 1000) %>%
     group_by(GeoUID, CSD_UID) %>%
    #  mutate_at(csdei, funs(ifelse(is.nan(.),0,.))) %>%
   mutate(smallh = ifelse(csdei == 0, NA, (ctpop*(csdei - ctei))/(csdei*csdpop)) ) %>%
    ungroup() %>%
    group_by(CSD_UID, csdei, name, csdpop) %>%
    mutate(smallhp = ifelse(is.na(smallh), 0, smallh)) %>%
  summarise(H = sum(smallhp)) %>% 
    mutate(cma = censuscode)
  
   cma.csd <- get_census("CA16", regions=list(CMA=censuscode), 
                        vectors = minority_vectors, level = "CSD",
                        labels = "short", geo_format = NA)
# 
#    segdata <- cma.csd %>% 
#     left_join(cma.h,  by = c("CSD_UID"="GeoUID")) %>% 
#     mutate()
#   
 
```

```{r segmap}

  pal <- colorQuantile(
     palette =  'Blues',
     domain = city_data$priceperroom,
     n = 10
   )
      pal2 <- colorQuantile(
     palette =  'Reds',
     domain = cma.h$H,
     n = 10)

#    map <- leaflet() %>% addProviderTiles("CartoDB.Positron") %>%
#       addPolygons(
#       data = csd.csd.geo,
#       color = 'black',
#       fill = F,
#       weight = 0.7,
#       opacity = 0.9
#     ) %>% addPolygons(
#       data = cma.h,
#       color =  ~ pal2(H),
#       fill = ~ pal2(H),
#        weight = 0.4
#     ) %>%
#   #addCircleMarkers(
#   #   data = city_data,
#   #       radius = ~ sqrt(4 * rooms),
#   #   lat = ~ latitude,
#   #   fillColor = ~ pal(priceperroom),
#   #   color = 'black',
#   #   stroke = T,
#   #   fillOpacity = 0.5,
#   #  weight = 0.1,
#   #   layerId = ~ id,
#   #   lng = ~ longitude
#   # ) %>% 
# # addLegend(pal = pal, position = 'topleft', values = city_data$priceperroom)%>% 
#   addLegend(pal = pal2, position = 'topleft', values = cma.h$H,n = 10)
#  
#    map
```


Let's use the information theory to qualify *diversity* and *segregation* of a given city (cf. John Iceland et al on multigroup entropy: https://www.census.gov/hhes/www/housing/resseg/multigroup_entropy.pdf). The measure have been implemented are described below and tested on Canadian metropolisis from package `cancensus` (example by @dshkol: https://github.com/dshkol/scratchpad/blob/master/content/post/2018-05-10-diversity-and-segregation-i.Rmd).

