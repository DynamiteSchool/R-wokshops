---
title: "ScrapFlightRadar"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, error=TRUE)

```

```{r, message=FALSE}
library(rvest)
library(tidyverse)
library(knitr)
library(plyr)
library(dplyr)
library(jsonlite)
library(lubridate)
```

# Scrape all departures or arrivals from FlightRadar website

We see two methods to capture departures and arrivals data for airport on FlightRadar website, using an headless browser, and using XHR request.

For each airports page, FlightRadar website offer the possibility to see general informations, departures and arrivals flights information. For this tutorial we try to scrape the [Bordeaux MÃ©rignac Airport BOD](https://www.flightradar24.com/data/airports/bod/) departures data [page](https://www.flightradar24.com/data/airports/bod/departures) and arrival flights [page](https://www.flightradar24.com/data/airports/bod/arrivals)

As you could see if you go to departures pages, you have two interesting buttons, one at the top of the page, and one at the bottom of the page. 

<img src='images/button_earlier.png'/>
<img src='images/button_later.png'/>

To display all data available (something like 24h of past and future departures/arrivals), we simulate multiples clic on this two buttons, and we stop this behavior only when this buttons disapear from the page.

## Using Selenium headless browser

Due to some defence created by webmaster to protect some data, you need to simulate an human behavior, if possible using a real browser. 


To be short, [Selenium](https://docs.seleniumhq.org/) is a multi-tools project focusing on task automation to test web aplication. It works with lots of Internet browsers, and lot of operating systems.  

In short, Selenium Webdriver give to developper an API to interact/pilot an headless internet browser without opening it. So, you, developper, you could use this API with your favorite langage (Java, Python, R, etc.) to sent commands to browser in order to navigate, move your mouse, click on DOM element, sent keyboard output to input forms, inject javascript, capture image of the page, extract html, etc.

First, you need to install and load RSelenium package, the R bindings library for Selenium Webdriver API : 

```R
install.packages("devtools")
devtools::install_github("ropensci/RSelenium")
```
Depending of your existing configuration and OS you probably need to install some dependent software packages.

```{r, message=FALSE}
library(RSelenium)
```

It's possible to use directly Selenium with your browser, but we prefer to use directly a server version. Why ? Because using server version of Selenium, you have the possibility a) to sent command on local or remote server running Selenium b) which run a different browsers and/or OS, c) to distribute tests over multiple machines.

Selenium is a fast moving project, and some release are really buggy, so try to choose a stable version, and don't deseperate.

### Run a Selenium server

Install Docker on your OS using docker documentation. 

When it's done, `pull and run` [one of](https://github.com/SeleniumHQ/docker-selenium) Docker Selenium-Server image using terminal. For this tutorial we use Firefox !

```bash
sudo docker run --name selenium -d -p 4445:4444 selenium/standalone-firefox:3.14.0-arsenic
```

Type `sudo docker ps` to see if server correctly run and listen to port 4445.

### Connect to Selenium Server

Connect and open the browser on the server.

```{r, message=FALSE, error=FALSE}
remDr <- remoteDriver(remoteServerAddr = "localhost", port = 4445L)
remDr$open()
remDr$maxWindowSize()
```

### Basic command for RSelenium

[Johnd Harrison](https://github.com/johndharrison), the creator and first commiter of RSelenium binding library for Selenium, create a big tutorial with lots of commands covered : https://rpubs.com/johndharrison/RSelenium-Basics

Some of them : 

- `remDr$maxWindowSize()` : maximize windows of the browser.
- `remDr$navigate("https://www.google.fr")` : navigate to url
- `remDr$screenshot(display = TRUE)` : take a screenshoot of the webpage and display it in RStudio Viewer
- `remDr$findElement(...)` : Find and element in the html structure, using different method : xpath, css, etc.
- `remDr$executeScript(...`) : Execute a js script in the remote browser

### Analyze html page structure !

Open `Web Developer tools` in your favorite browser on the arrivals webpage of BOD : `https://www.flightradar24.com/data/airports/bod/arrivals`

We investigate what happens in the html code when the load earlier or load later button . Why we do that ? To understand how we could automate things.

Because we want to automate clic on this two buttons, so we need to understand WHEN we need to stop clicking :) If we clic an infinite number of time, an error probably trigger when one of the two button disapear.

Select the Selector tools (sic) and click on the load earlier flights button.

<img src='images/webdeveloper.png'/>

If you clic the right thing, normaly you have highlighted some part of the html code which interest us :

<img src='images/selected_earlier.png'/>

Now, Iif you highlight and clic with the web tool selector on the load later flights button, you have something like that : 

<img src='images/selected_later.png'/>

Things are not so very differences between this two buttons objects. It seems that only the timestamp, the data page number and the button text change ...

Hightlight and clic one more time on the *load earlier flights* button. Clic another time to load a new page of data. You see that the html code change during the data load to desactivate clic on the button. Not so interesting. Now repeat the clic and stop only when the button disapear on your screen. 

<img src='images/button_disapear.png'/>

Great, a new css style attribute appear to indicate that now this button object is hidden : `style="display: none;"`

How could we re-use this important information during data harvesting to detect if the button is activated/desactivated ? The best solution was to use XPATH query !

Load the page in the selenium server 

```{r, message=FALSE}
remDr$navigate("https://www.flightradar24.com/data/airports/bod/arrivals")
Sys.sleep(5) # time to load !
remDr$screenshot(file = "screenshoot.png")
```

Building XPATH correct expression could be difficult. A good way to test validity of your XPATH expressions was to use an interactive way, with web developper console. 

Clic on console tab :

<img src='images/console.png'/>

Type this in the console : `$x("//button[@class='btn btn-table-action btn-flights-load']")`

The result is an interactive array you could develop as a tree if you want.

<img src='images/console_with_xpath.png'/>

Clic Clic Clic to make disapear one of the loading button, and now we trying to select only the available button. XPATH understand boolean operator (or,and, etc.) so we filter by `@class` and `style` :

`$x("//button[@class='btn btn-table-action btn-flights-load' and contains(@style,'display: none;')]")`

Great, this query return only the valid button. We use later this query to stop our loop of infernal button clic.

Now we try to build this query using RSelenium with `findElement()` function : 

```{r, message=FALSE}
loadmorebutton <- remDr$findElements(using = 'xpath', "//button[@class='btn btn-table-action btn-flights-load' and not(contains(@style,'display: none;'))]")
```

Display the text of each element retrieved by function `findElements()` using the `getElementText() function`

```{r, message=FALSE}
unlist(lapply(loadmorebutton, function(x){x$getElementText()}))
```

Now, how to simulate a clic on one of this button ?

An easy way was to call `clickElement()` function on the first loadmorebutton webelement :

```{r, message=FALSE}
tryCatch({
suppressMessages({
  loadmorebutton[[1]]$clickElement()})},
error = function(e) {
    loadmorebutton[[1]]$errorDetails()$message
  })
```

This command return an error message (if not, you're lucky !), not very explicit, so if you want more details, you could call the function `errorDetails()` like our `trycatch` block.

An element of the webpage overlapp our button, so browser say us that's not possible to clic on this webelement. Use snapshot function to see the page : 

```{r, message=FALSE}
remDr$screenshot(file = 'screenshoot_overlap.png' )
```

If we hide these elements using XPath and javascript injection, everything goes to normal. First we accept cookies.

```{r, message=FALSE, delay = TRUE}
hideCookie <- function (x){
  cookiesButton <- x$findElement(using = 'xpath',"//div[@class='important-banner__close']") 
  cookiesButton$clickElement()
}

hideCookie(remDr)
remDr$screenshot(file = 'screenshoot_hide.png')
```

The navbar element create problem, so we hide it using javascript injection :

```{r, message=FALSE, delay = TRUE}
hideNavBar <- function (x) {
  script <- "document.getElementById('navContainer').hidden = true;"
  x$executeScript(script)
}
hideNavBar(remDr)
```

Now you can `clickElement()` without problem :)

```{r, message=FALSE}
tryCatch({
suppressMessages({
  loadmorebutton[[1]]$clickElement()})},
error = function(e) {
    remDr$errorDetails()$message
  })
```

See changes before and after using `remDr$screenshot(display = TRUE)` command

### Exercices

- Create a function which clic on button until they all disapears  :)

<button title="Click to show answer" type="button"
   onclick="if(document.getElementById('spoiler').style.display=='none')
              {document.getElementById('spoiler').style.display=''}
            else{document.getElementById('spoiler').style.display='none'}">
  Show/hide
</button>

<div id="spoiler" style="display:none">


```{r, message=FALSE}
 remDr$refresh() # reload page
 Sys.sleep(5) # time to load !
 
 hideNavBar(remDr) 
 
 searchElements <- function() { 
   elements <- remDr$findElements(using = 'xpath', "//button[@class='btn btn-table-action btn-flights-load' and not(contains(@style,'display: none;'))]")
   return(elements)
   }
 
clic <- function(x){
  print(paste("Clic on ", x$getElementText() ," button")) 
  x$clickElement()
  Sys.sleep(5) # time to load
 }
 
loadmorebutton <- searchElements()
nbElements <- length(loadmorebutton)

while( nbElements > 0)
{  
   print(paste("nb of button >", nbElements))
   lapply(loadmorebutton, clic)
   Sys.sleep(5) # time to load
   loadmorebutton <- searchElements()
   nbElements <- length(loadmorebutton)
}


```

But we only have the number of clic and screenshot return only part of the viewer. In the next exercice we try to return all data on the page for the first result day after all these clics.

</div>

- Extract data for only one day using XPATH and Rvest !

<button title="Click to show answer" type="button"
   onclick="if(document.getElementById('spoiler2').style.display=='none')
              {document.getElementById('spoiler2').style.display=''}
            else{document.getElementById('spoiler2').style.display='none'}">
  Show/hide
</button>

<div id="spoiler2" style="display:none">

We use the already discussed library nammed `rvest` to prepare data for dataframe.

```{r, message=FALSE}

src <- remDr$getPageSource()[[1]]  %>% read_html()

searchDateElements <- function() { 
   elements <- remDr$findElements(using = 'xpath',"//*[contains(@class,'row-date-separator')]/td")
   return(elements)
}

# get the first date
flightDateElements <- searchDateElements()
flightDate <- flightDateElements[[1]]$getElementText()[[1]]

column <- function(x) src %>% html_nodes(xpath = x) %>% html_text(trim=TRUE)

df <- data.frame(
  hour = column(paste("//tr[@data-date='",flightDate,"']//td[1]/text()",sep="")),
  from = column(paste("//tr[@data-date='",flightDate,"']//span[@class='hide-mobile-only ng-binding']/text()",sep="")),
  code = column(paste("//tr[@data-date='",flightDate,"']//div[@ng-show='(objFlight.flight.airport.origin)']//a//text()",sep="")),
  airline = column(paste("//tr[@data-date='",flightDate,"']//td[@class='cell-airline']//a//text()",sep="")),
  plane = column(paste("//tr[@data-date='",flightDate,"']//span[@class='notranslate ng-binding']/text()",sep="")),
  planecode =column(paste("//tr[@data-date='",flightDate,"']//a[@ng-show='(objFlight.flight.aircraft.registration)']//text()",sep="")),
  info = column(paste("//tr[@data-date='",flightDate,"']//td[7]",sep="")),
  stringsAsFactors = FALSE
)

kable(df,caption ="results of webscraping")

```

</div>

## Using XHR request

https://www.w3schools.com/js/js_json_http.asp

Sometimes, a defence is also a point of vulnerability. Many site use an internal API to query and feed website. 

We try to see if this is the case with flight radar :)

Open the dev tools in the browser, clic on Network tab, then XHR tab.

<img src='images/XHR.png'/>

Lucky guy/girl, do you see it ? Each `GET` query call an `aiport.json` file on the server :

`https://api.flightradar24.com/common/v1/airport.json?code=bod&plugin[]=&plugin-setting[schedule][mode]=&plugin-setting[schedule][timestamp]=1537297562&page=1&limit=100&token=`

If we decompose the query, we have :
- an airport code : **bod**
- a timestamp : **1537297562**
- a page number : **1**
- a limit by page : **100**

Copy paste this url in your browser to see how the result json is structured. Insteresting data is located into schedule `result > response > airport > arrivals` : 
- **item :** number of total items
- **page :** actual page and number of page 
- **timestamp :** date of capture
- **data :** a list of 100 flights corresponding to actual page

We download and convert json data to data.frame using the jsonlite wonderfull package :) Why wonderfull ? Because jsonlite had an option to flatten the structure of json which normally contain data.frame into data.fram into data.frame ... 

```{r, message=FALSE}

timestamp <- as.numeric(as.POSIXct(now()))

url <- paste("https://api.flightradar24.com/common/v1/airport.json?code=bod&plugin[]=&plugin-setting[schedule][mode]=&plugin-setting[schedule][timestamp]=",timestamp,"&page=1&limit=100&token=",sep="")

# https://cran.r-project.org/web/packages/jsonlite/vignettes/json-aaquickstart.html
json <- jsonlite::fromJSON(url,flatten = T) 
```


```{r, message=FALSE}
pageOfData <- json$result$response$airport$pluginData$schedule$arrivals$data 
filteredData <- pageOfData %>% select(flight.airline.code.icao, flight.airline.name, flight.airport.origin.name, flight.airport.origin.code.icao, flight.airport.origin.position.latitude, flight.airport.origin.position.longitude) 

filteredData <- rename(filteredData, c(flight.airline.code.icao = "ICAO", flight.airline.name= "Name", flight.airport.origin.name = "Origin", flight.airport.origin.code.icao="Origin ICAO", flight.airport.origin.position.latitude = "Latitude",flight.airport.origin.position.longitude = "Longitude" ))

knitr::kable(filteredData, caption = "page 1 of arrival for BOD")

```

### Exercices

- Get all pages of data by generating the correct query to API :)

## Docker !

This is the ultimate and probably the most complex part of this big tutorial.

In real webscraping project, there are two possible use case : a one shoot harvest, or a daily/monthly/etc. harvest of data.

If you need to collect **one year of data on a daily basis**, you cannot use your personnel computer. You need to connect and run your from a distant server.

To be really really short on subject, Docker is a technology which encapsulate your software into an isolated (and if possible immutable) container on the top of your system. The concept is similar to virtual machine (VM), but more efficient.

Here we are, we use this Docker container technology to encapsulate a webscrapping script. After that you could save your and launch it on a webserver.

There are three big step to understand in container lifecycle: 

- We describe the composition of an **image** into a **Dockerfile** file using special Docker syntax. It's like a recipe into cookbook. For example, you could find lot of recipes on this site : DockerHub.

- Next, like a recipe in the real life, you need to concretize this recipe into some delicious cake. Image need to be built before usage. 

- Finally, you run the builted image.


### Linux way

**PREPARE image**

Open your linux terminal.
Go to `docker-scripts` folder into the folder which contain this tutorial on your disk.

**BUILD image**

The building of this image take lot of times (ten minutes), this is due to the huge dplyr library. Run the `docker build` command in the folder which contain the `Dockerfile` description of the image.

```bash
docker build . --tag=rflightscraps
```

**LAUNCH IMAGE**

a) Using a **binded volume**, this is the easiest way actually. Open your terminal, go to the folder of your script. Create a new folder named `localbackup` and run the container `rflightscraps` with correct path.

```bash
mkdir localbackup
docker run --name rflightscraps -d -e UID=1000 -e GID=1000 --mount type=bind,source=$(pwd)/localbackup,destination=/usr/local/src/flight-scrap/docker-scripts/data rflightscraps --name rflightscraps
```

To see if your container is running and consult the logs of execution : 

```bash
sudo docker ps
sudo docker logs rflightscraps
```

To consult the result of automatic harvesting, consult the `docker-scripts/localbackup` folder using `ls` unix command. You see a list of csv which correspond to harvest made every minute. If you want to change this, you need to modify the `crontab` file following the [cron syntax](https://crontab.guru/#*_*_*_*_*), and rebuild/relaunch the image (it take less time, because you only modify one file, no need to recompile).


b) Same thing, but using a *named volume*, a more portable way to share data between docker container, but it lacks some features on permissions to correctly export data.

Create a named volume, independent from filesystem

```bash
docker volume create --name myDataVolume
docker volume ls
```

Mount the volume : 

```bash
docker run --mount type=volume,source=myDataVolume,destination=/usr/local/src/flight-scrap/docker-scripts/data rflightscrap
```

Export data  : 

- Using a `alpine` image, we mount the named volume (`myDataVolume`) to a `/alpine_data` folder inside the `alpine` container.

- Then, we create a new folder inside the `alpine` container named `/alpine_backup`.

- We then create an archive containing the contents of the `/alpine_data` folder and we store it inside the `/alpine_backup` folder (inside the container).

- We also mount the `/alpine_backup` folder from the container to the docker host (your local machine) in a folder named `/local_backup` inside the current directory.


```docker run --rm -v myDataVolume:/alpine_data -v $(pwd)/local_backup:/alpine_backup alpine:latest tar cvf /alpine_backup/scrap_data_"$(date '+%y-%m-%d')".tar /alpine_data```

```{r, message=FALSE}
remDr$close()
```



